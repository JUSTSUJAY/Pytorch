{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc6ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce2e25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__()\n",
    "#         convolutional layers\n",
    "#         input - 1 image , output - 6 images, filters - 5x5\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "#         fully connected layers\n",
    "        self.fc1 = nn.Linear(16*5*5, 120) # 5*5 image dimens\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = NN()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ff5a7",
   "metadata": {},
   "source": [
    "You just have to define the forward function, and the `backward` function (where gradients are computed) is automatically defined for you using `autograd`. You can use any of the Tensor operations in the forward function.\n",
    "\n",
    "The learnable parameters of a model are returned by `net.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0451272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())\n",
    "print(params[1].size())\n",
    "print(params[2].size())\n",
    "\n",
    "print(params[3].size())\n",
    "print(params[4].size())\n",
    "print(params[5].size())\n",
    "\n",
    "print(params[6].size())\n",
    "print(params[7].size())\n",
    "print(params[8].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc188a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.1129, -0.1543,  0.1894, -0.0873,  0.0558],\n",
      "          [ 0.1122,  0.0764,  0.0842, -0.1780, -0.0038],\n",
      "          [ 0.1025,  0.1396,  0.1447,  0.1959,  0.0023],\n",
      "          [ 0.1412, -0.1511, -0.0797, -0.0573,  0.0873],\n",
      "          [ 0.0733,  0.0653,  0.0248,  0.1874,  0.0979]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2000, -0.0453,  0.0401, -0.0214,  0.0733],\n",
      "          [-0.1756, -0.0392,  0.1902,  0.0837, -0.0861],\n",
      "          [ 0.1155,  0.0031, -0.0609, -0.0369,  0.0726],\n",
      "          [-0.1490, -0.1675, -0.1598,  0.0702,  0.0430],\n",
      "          [-0.1798, -0.1586,  0.0250,  0.0433, -0.1062]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0743,  0.1898,  0.0143,  0.1941,  0.0569],\n",
      "          [-0.1562,  0.0343, -0.1326,  0.1083,  0.1096],\n",
      "          [ 0.0588, -0.1843,  0.0973,  0.0279,  0.1441],\n",
      "          [-0.0956,  0.1857,  0.0722,  0.1358, -0.0069],\n",
      "          [-0.0865,  0.1120, -0.1386, -0.1523, -0.0560]]],\n",
      "\n",
      "\n",
      "        [[[-0.0784,  0.0010, -0.1464, -0.0872,  0.0580],\n",
      "          [ 0.0723,  0.1299, -0.1781, -0.1723, -0.0469],\n",
      "          [ 0.0713, -0.0187,  0.1555, -0.0338, -0.1077],\n",
      "          [-0.1957,  0.0812,  0.1662, -0.0466, -0.1064],\n",
      "          [-0.1407,  0.0326, -0.1933,  0.0645, -0.0430]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0815, -0.0931,  0.1185, -0.1230, -0.0720],\n",
      "          [-0.0054, -0.0556,  0.1884, -0.1702,  0.0251],\n",
      "          [-0.1326,  0.0986,  0.0341,  0.1187, -0.0701],\n",
      "          [ 0.1689,  0.0805, -0.1190,  0.0272,  0.0840],\n",
      "          [ 0.1270, -0.0694,  0.0977, -0.1716, -0.0352]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0153,  0.0225,  0.0907, -0.0631, -0.1841],\n",
      "          [ 0.0662,  0.1782,  0.0847,  0.0796,  0.0824],\n",
      "          [ 0.1712, -0.0426,  0.1201,  0.0750,  0.0115],\n",
      "          [ 0.1404,  0.1014,  0.0917, -0.0181,  0.0355],\n",
      "          [-0.0197, -0.1220,  0.0916,  0.1591,  0.1115]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0782, -0.1741, -0.1019, -0.0864, -0.1110,  0.0030],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-1.6059e-02, -1.3728e-02,  2.3873e-03,  2.0304e-02,  1.0744e-02],\n",
      "          [-5.5464e-02, -5.8609e-02,  4.8891e-02, -6.2420e-02,  4.2103e-02],\n",
      "          [-4.7591e-02, -7.4889e-02,  4.8425e-02,  6.6552e-02,  2.8690e-03],\n",
      "          [-7.9719e-02, -1.2565e-02,  2.7065e-02, -3.4453e-02,  9.7129e-03],\n",
      "          [ 2.6650e-02,  3.2661e-02, -5.7252e-02, -3.5555e-02,  1.5173e-02]],\n",
      "\n",
      "         [[-1.5862e-02,  2.3435e-03, -9.6199e-03, -3.3217e-02, -5.8481e-02],\n",
      "          [-6.3385e-02, -1.5548e-03,  3.4982e-02,  2.1934e-02,  6.7140e-02],\n",
      "          [ 3.7465e-02,  7.0575e-02, -9.3374e-03,  7.8060e-02, -5.8054e-02],\n",
      "          [ 5.6056e-02,  3.4122e-02,  5.7471e-03,  2.1370e-02,  4.1639e-02],\n",
      "          [-2.3541e-02, -1.0118e-02,  6.4762e-02, -3.4875e-02,  3.9816e-02]],\n",
      "\n",
      "         [[-3.2522e-02, -3.2627e-02,  2.1762e-02, -1.2027e-02, -3.4652e-02],\n",
      "          [ 3.9625e-03, -2.5137e-02, -7.8076e-02, -6.4283e-02, -5.6552e-02],\n",
      "          [ 1.9500e-02,  7.8709e-02, -6.9542e-02,  7.9969e-02,  5.4023e-02],\n",
      "          [ 5.7753e-02,  5.9108e-02,  6.8000e-03,  5.2399e-02,  6.3004e-02],\n",
      "          [ 1.7043e-03, -7.1758e-02, -5.0750e-02, -5.7986e-02,  5.2635e-02]],\n",
      "\n",
      "         [[ 5.5736e-02,  2.9736e-02,  5.0459e-02, -3.6132e-02, -4.0955e-03],\n",
      "          [-2.7145e-02,  2.8022e-02, -4.0671e-02, -3.4816e-02, -4.1302e-02],\n",
      "          [-4.6350e-02,  7.5335e-02,  7.7501e-02, -7.0985e-02, -9.5335e-03],\n",
      "          [ 6.0888e-02, -5.2862e-02, -2.6732e-02, -6.2158e-02, -1.5045e-02],\n",
      "          [-5.2567e-03, -4.5839e-02,  7.0386e-04, -2.6710e-02, -1.8912e-02]],\n",
      "\n",
      "         [[-4.8313e-02,  3.6158e-02, -5.0565e-02, -3.2988e-02,  7.5616e-02],\n",
      "          [-4.1440e-02, -6.2815e-03,  6.4754e-02,  5.8323e-02, -1.7511e-02],\n",
      "          [ 5.7267e-02,  3.4847e-02, -3.5138e-02,  6.0680e-02,  7.8155e-02],\n",
      "          [-5.4653e-02,  6.7374e-02,  3.2320e-02, -5.6084e-02,  3.6784e-02],\n",
      "          [-7.6556e-02, -6.7581e-03, -2.6569e-02, -6.3569e-02, -5.2563e-02]],\n",
      "\n",
      "         [[ 4.7173e-02,  1.7004e-02, -7.7312e-02,  7.7039e-02, -7.9075e-03],\n",
      "          [-4.6774e-02,  5.4498e-02, -5.9962e-02,  3.0116e-02,  4.6757e-02],\n",
      "          [ 6.0201e-02,  6.5276e-02, -4.6498e-02, -2.4027e-02,  5.4829e-02],\n",
      "          [-2.5361e-02,  2.3316e-02, -1.0748e-02, -7.8262e-02,  2.5924e-03],\n",
      "          [-3.1166e-02, -3.4159e-02, -5.6966e-02,  8.1064e-02,  7.4758e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.0130e-02,  5.8912e-03, -1.6463e-02,  6.9949e-02, -5.5789e-02],\n",
      "          [ 4.0251e-02,  4.0096e-02,  5.8771e-03, -4.7162e-02, -2.6677e-02],\n",
      "          [-1.1188e-02,  3.1917e-02, -4.7574e-02,  1.1913e-02, -1.4398e-02],\n",
      "          [-7.5114e-02,  1.5844e-02,  2.1982e-03, -3.1933e-02,  3.1291e-02],\n",
      "          [ 1.7247e-02,  2.9211e-02,  1.7337e-02,  1.0014e-02, -4.0703e-02]],\n",
      "\n",
      "         [[-5.3236e-02, -2.7926e-03,  6.1527e-02,  1.0893e-02,  6.7621e-02],\n",
      "          [-1.3073e-02,  3.3022e-02, -4.4635e-02,  4.7285e-02, -4.9910e-02],\n",
      "          [-7.8545e-02,  8.1246e-02, -5.2029e-02, -1.5508e-02,  5.3920e-05],\n",
      "          [-2.3060e-02, -2.1250e-02, -5.7177e-03, -6.3420e-02, -6.8161e-02],\n",
      "          [-1.1776e-02,  4.4470e-02,  2.5279e-02,  3.9963e-02, -6.5569e-02]],\n",
      "\n",
      "         [[-6.4704e-03, -2.3701e-03,  3.6589e-02, -2.4555e-02, -3.8071e-03],\n",
      "          [ 2.6962e-02,  7.0384e-02, -1.7654e-02,  7.7203e-02,  6.6998e-02],\n",
      "          [-1.4827e-02,  5.1332e-02,  3.7387e-02, -7.9162e-02, -2.7073e-02],\n",
      "          [ 3.0195e-02, -6.9961e-02,  1.1028e-02, -7.3991e-02, -1.1523e-02],\n",
      "          [-5.6685e-02, -2.7721e-02,  3.8041e-02, -7.3654e-02,  5.2247e-02]],\n",
      "\n",
      "         [[-5.2900e-02, -3.7443e-02, -5.4137e-03,  4.8212e-02,  3.0025e-02],\n",
      "          [ 8.1533e-02,  4.8417e-02, -1.9643e-02, -1.0959e-02, -5.6767e-02],\n",
      "          [-4.0046e-02,  5.6684e-02,  1.0636e-02,  1.5736e-02, -8.1319e-02],\n",
      "          [ 4.9453e-02,  5.2379e-02,  5.9706e-03, -3.6670e-02, -5.0906e-02],\n",
      "          [ 1.4887e-02,  4.0309e-02,  5.4198e-02, -6.7674e-05,  2.7588e-02]],\n",
      "\n",
      "         [[ 5.0760e-03,  6.7421e-02,  7.1628e-02, -7.3457e-02,  4.5444e-02],\n",
      "          [ 7.0064e-02,  2.5651e-03,  8.8647e-03,  6.6134e-02, -3.6966e-02],\n",
      "          [-6.3605e-02,  5.1531e-02,  1.2377e-02, -3.6183e-02, -4.3628e-02],\n",
      "          [ 4.5572e-02, -6.1618e-02,  6.8817e-02, -2.5762e-02, -4.3117e-02],\n",
      "          [-4.4603e-02, -6.1271e-02,  1.6057e-02, -7.1678e-02, -2.7769e-02]],\n",
      "\n",
      "         [[-3.2293e-02,  6.4313e-02,  3.8720e-02, -3.7835e-02, -9.6617e-03],\n",
      "          [ 2.5904e-02, -2.3990e-02,  8.1424e-02,  3.9530e-02,  3.5824e-02],\n",
      "          [ 3.8787e-02,  5.4074e-02,  7.3681e-03, -3.6888e-02, -5.1310e-02],\n",
      "          [ 4.5302e-02,  1.3076e-02, -4.9070e-02,  3.2837e-02,  4.9287e-02],\n",
      "          [-6.5460e-02, -3.4424e-02,  6.4070e-02,  4.7552e-02,  3.6182e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7920e-02,  7.2705e-02,  3.7276e-02, -3.3843e-02,  4.7706e-02],\n",
      "          [ 9.5356e-03, -6.5187e-02,  1.4310e-03,  1.3228e-04,  3.6636e-02],\n",
      "          [-4.4454e-02,  6.6071e-02, -6.2656e-02, -2.9635e-02, -4.6927e-02],\n",
      "          [ 7.9127e-02, -3.0850e-02, -5.3835e-02, -7.5279e-03,  5.1202e-02],\n",
      "          [-4.8587e-02,  3.3387e-02, -6.3178e-02,  6.6225e-02, -6.3516e-02]],\n",
      "\n",
      "         [[ 4.1639e-02,  5.6419e-02,  5.5493e-02, -2.0606e-02, -7.6580e-02],\n",
      "          [ 7.9223e-02, -8.6227e-04, -2.3202e-02,  2.1490e-03,  2.2845e-02],\n",
      "          [-4.8110e-02, -8.0730e-02, -1.8667e-02, -2.9812e-03, -5.2839e-02],\n",
      "          [ 7.0875e-02,  5.4440e-02, -3.3152e-03,  1.6445e-02, -8.0431e-02],\n",
      "          [-5.7817e-03, -7.3847e-02, -7.7313e-02,  3.7322e-03, -1.0944e-02]],\n",
      "\n",
      "         [[ 2.7533e-03,  5.6597e-02,  1.6521e-02,  3.7798e-02, -2.1256e-02],\n",
      "          [ 6.1166e-02, -7.6834e-02, -4.5657e-02, -6.4695e-02,  5.6578e-02],\n",
      "          [-8.3245e-04, -1.5574e-02,  5.7525e-02, -5.4595e-02, -2.2580e-03],\n",
      "          [-3.4763e-02,  7.0695e-02, -1.2903e-02, -7.5583e-02,  2.2227e-02],\n",
      "          [-2.8208e-02, -1.2177e-03, -3.8122e-02,  3.9995e-02,  5.2099e-02]],\n",
      "\n",
      "         [[ 7.3152e-02,  7.2125e-02,  4.8131e-02, -4.7455e-02,  6.6403e-02],\n",
      "          [-5.3570e-02, -6.5390e-03, -7.2341e-02, -8.0893e-02,  3.8078e-03],\n",
      "          [ 6.8884e-03,  4.3009e-02,  7.4049e-02,  7.1859e-02, -3.2523e-02],\n",
      "          [ 8.3429e-04, -7.4642e-02, -2.3094e-04, -2.9457e-02, -2.4191e-02],\n",
      "          [-3.8661e-02,  7.9118e-03,  1.2319e-03,  4.6884e-03, -7.1500e-02]],\n",
      "\n",
      "         [[ 5.6624e-02,  1.7363e-02,  1.4136e-02, -2.4015e-02,  2.5585e-02],\n",
      "          [-7.7863e-02, -4.8604e-02,  7.7161e-02,  4.5019e-02,  2.8139e-02],\n",
      "          [ 7.2329e-02,  1.8579e-02, -5.5740e-02, -6.7997e-02, -7.6393e-02],\n",
      "          [-1.4186e-02, -3.9263e-02,  7.3474e-02,  4.9324e-02, -2.7981e-02],\n",
      "          [ 5.9725e-02, -7.2053e-02, -2.2738e-02, -7.2222e-02,  6.5882e-02]],\n",
      "\n",
      "         [[-2.8273e-02,  4.4807e-02, -5.5747e-02,  4.0643e-03, -7.9676e-03],\n",
      "          [ 9.2702e-03, -8.6051e-03,  3.4254e-02,  7.8267e-02,  5.1088e-02],\n",
      "          [-4.6558e-02, -1.7793e-02, -7.4228e-02, -3.1129e-02,  4.5551e-02],\n",
      "          [-5.9976e-02,  3.6507e-02, -8.1437e-02,  1.7511e-02,  4.1047e-02],\n",
      "          [ 5.1097e-02, -6.2332e-02,  2.6691e-02,  6.6035e-02, -7.3988e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.2549e-02, -4.4884e-02, -5.1145e-02, -6.8494e-02,  1.0091e-02],\n",
      "          [ 2.9818e-02, -2.3576e-02, -3.3358e-02, -2.4646e-02,  1.8033e-02],\n",
      "          [-6.9228e-02, -7.8914e-02, -1.4103e-02, -1.0370e-02, -6.1192e-02],\n",
      "          [-2.0968e-02,  5.6885e-02,  5.7345e-02,  1.2209e-03, -4.8303e-02],\n",
      "          [-5.1766e-02,  5.7860e-03,  2.6619e-02, -5.4498e-02, -7.9660e-02]],\n",
      "\n",
      "         [[ 3.9060e-02,  4.9109e-02, -3.5364e-02,  7.6817e-02, -2.4683e-02],\n",
      "          [ 6.4304e-02,  1.8465e-02, -2.2322e-04, -2.3002e-02,  3.1930e-02],\n",
      "          [-5.6739e-02, -7.6526e-02,  2.2131e-02, -7.4180e-02, -6.5275e-02],\n",
      "          [ 6.7128e-02, -4.8407e-02, -5.1443e-02,  3.9933e-02, -7.3214e-02],\n",
      "          [ 1.2329e-02, -7.6933e-02,  5.2381e-02,  3.2969e-02, -7.8208e-03]],\n",
      "\n",
      "         [[-7.8667e-02, -7.3454e-02, -7.6558e-02, -6.7456e-02,  1.3189e-02],\n",
      "          [-3.6935e-02, -4.8985e-02, -5.6000e-02, -1.0068e-02, -3.7748e-02],\n",
      "          [ 3.2514e-02, -3.1180e-03, -1.8111e-02,  8.0468e-02, -5.1040e-02],\n",
      "          [ 4.4385e-02, -6.1371e-02,  7.1005e-02, -6.3990e-02, -5.4814e-02],\n",
      "          [ 6.4799e-02, -7.9319e-02,  1.9742e-02, -6.0017e-02,  7.8893e-02]],\n",
      "\n",
      "         [[ 7.6284e-04,  2.1445e-02, -3.3456e-02,  7.1990e-02, -1.8303e-02],\n",
      "          [-3.7650e-02, -4.8978e-02,  2.8239e-02,  1.8931e-03, -6.7362e-02],\n",
      "          [ 3.4735e-02, -7.2443e-02,  1.7032e-02, -5.0304e-02, -2.8944e-02],\n",
      "          [ 1.0300e-02, -4.9405e-03, -7.6217e-02, -6.9629e-02, -5.0303e-02],\n",
      "          [-1.1379e-02, -7.5812e-02, -1.4436e-02,  1.8965e-02,  2.5571e-02]],\n",
      "\n",
      "         [[ 1.1125e-02, -3.6850e-02,  6.8902e-02,  7.3046e-02, -1.4765e-02],\n",
      "          [-2.7480e-02, -4.0398e-02,  8.3903e-03,  1.2356e-02,  1.4154e-02],\n",
      "          [-7.5796e-03, -4.6374e-02,  5.0910e-02,  1.7623e-02, -6.4787e-02],\n",
      "          [ 5.7334e-02,  1.8727e-02, -3.2895e-02,  3.5750e-03, -3.0882e-02],\n",
      "          [-4.2688e-02, -6.6584e-02, -2.9659e-02, -1.4276e-02, -6.3071e-02]],\n",
      "\n",
      "         [[-2.2589e-04,  5.5178e-02,  3.9634e-02,  2.3456e-02, -6.0106e-02],\n",
      "          [ 2.4496e-02,  2.4881e-02,  2.0849e-02,  2.4947e-02, -6.0784e-02],\n",
      "          [-2.5605e-02,  6.9524e-02,  4.0802e-02, -4.2117e-02, -6.6514e-02],\n",
      "          [-3.9850e-02, -7.2141e-02,  1.9032e-02, -7.8055e-02, -5.4261e-03],\n",
      "          [ 1.0844e-02,  6.4530e-02,  5.8938e-02, -5.7825e-02, -6.4610e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2297e-02,  3.5613e-02,  2.2426e-02,  6.9403e-02, -7.5079e-02],\n",
      "          [-1.6465e-02,  7.6770e-02, -4.4995e-02,  9.0948e-03, -5.7823e-02],\n",
      "          [-4.0988e-02,  5.6799e-02,  3.4549e-02, -3.3771e-03,  7.4645e-02],\n",
      "          [ 1.0575e-03, -3.6478e-02,  3.9220e-02, -2.0514e-03, -2.3194e-02],\n",
      "          [-6.8029e-02,  8.9992e-03,  7.3100e-02, -5.4753e-03,  5.1831e-02]],\n",
      "\n",
      "         [[-4.0940e-02, -4.7762e-02,  3.3513e-02,  7.1912e-02,  2.1762e-02],\n",
      "          [-4.2453e-02,  3.5953e-02,  2.3324e-03,  2.9028e-03,  4.2432e-02],\n",
      "          [-5.7062e-02, -2.2678e-02, -1.9751e-02, -1.3051e-02, -2.2684e-02],\n",
      "          [-7.1577e-02, -4.4079e-02,  5.0373e-02, -4.5270e-02, -1.3465e-02],\n",
      "          [-7.1005e-04,  2.9686e-02,  1.3933e-02,  5.8436e-02, -3.7607e-02]],\n",
      "\n",
      "         [[ 2.6369e-02, -1.8506e-02,  4.2467e-02, -5.9284e-03,  6.9904e-02],\n",
      "          [ 1.5599e-03,  3.9066e-03,  6.5086e-02, -2.3222e-03, -6.9204e-02],\n",
      "          [ 4.3545e-02,  7.0102e-02,  4.2092e-02,  3.8557e-02,  5.2845e-02],\n",
      "          [ 2.1811e-03, -9.2323e-03, -7.7224e-02, -6.0217e-02,  6.4967e-02],\n",
      "          [ 5.7886e-02,  7.5021e-03, -6.8178e-02,  5.9378e-02, -8.1029e-02]],\n",
      "\n",
      "         [[-4.9911e-02, -7.4645e-02,  1.6755e-02, -7.6100e-02,  7.8216e-02],\n",
      "          [ 3.5942e-02,  5.4553e-02, -2.3024e-02,  7.2067e-02,  4.9372e-02],\n",
      "          [ 2.6512e-02,  5.2947e-02, -7.5290e-02,  1.0598e-02, -5.5351e-02],\n",
      "          [-6.9796e-02, -3.3486e-02,  4.5270e-02, -4.1760e-02,  3.7309e-02],\n",
      "          [-3.7144e-02,  7.7987e-03,  4.9526e-02,  2.1158e-02, -5.3900e-02]],\n",
      "\n",
      "         [[ 4.6438e-03,  3.0884e-02,  8.3504e-03, -1.4925e-02,  6.3977e-03],\n",
      "          [ 3.6455e-02,  1.4993e-02, -7.6749e-02, -6.5414e-02, -7.4072e-02],\n",
      "          [-2.9573e-02, -6.5019e-02, -4.7771e-03,  5.4210e-02,  6.4915e-02],\n",
      "          [-1.2203e-02,  6.9531e-02,  7.9881e-02, -3.1523e-02, -4.1387e-02],\n",
      "          [ 7.3630e-02, -6.5294e-02, -8.9645e-05, -7.8980e-02,  2.1293e-02]],\n",
      "\n",
      "         [[ 1.7876e-02, -5.2079e-02,  7.5688e-02,  1.7705e-02, -4.9518e-02],\n",
      "          [-2.1307e-02,  2.2278e-02,  5.6831e-02, -7.9155e-02,  2.7491e-03],\n",
      "          [-3.9598e-02,  2.0027e-02, -6.2424e-02, -6.0434e-02,  7.7414e-02],\n",
      "          [ 1.4082e-02, -1.0099e-02, -1.7948e-02,  1.3770e-02,  6.6382e-02],\n",
      "          [-7.6951e-02, -4.0681e-02,  7.9681e-02, -4.1246e-02, -7.2813e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3150e-02,  2.2795e-02, -7.0031e-02, -6.3643e-02, -3.2572e-02],\n",
      "          [ 6.2443e-04,  1.2774e-02, -6.0126e-02, -2.4792e-02, -5.5356e-02],\n",
      "          [ 1.1137e-02, -7.8974e-02, -3.8722e-02, -8.0700e-02, -7.6137e-02],\n",
      "          [-4.4691e-02,  4.8465e-02,  7.1804e-02,  4.4083e-03,  5.5165e-02],\n",
      "          [ 4.0933e-02, -7.3495e-02,  8.3592e-03, -3.2162e-02,  4.4489e-02]],\n",
      "\n",
      "         [[ 4.8876e-02, -2.3790e-02,  4.7324e-02,  1.9769e-02,  1.1454e-02],\n",
      "          [ 1.5909e-02,  1.4976e-02,  5.3811e-02,  7.5468e-02,  7.3957e-02],\n",
      "          [ 4.6073e-02, -2.4803e-02,  1.2098e-02, -9.3025e-03, -2.9326e-02],\n",
      "          [-7.2819e-02, -5.0882e-02,  8.8941e-03, -1.0765e-02, -4.4121e-02],\n",
      "          [-6.1680e-02, -5.9542e-02, -7.4164e-02, -7.3853e-02,  7.4681e-02]],\n",
      "\n",
      "         [[-2.5140e-02, -4.0865e-02, -6.5378e-02,  1.8411e-02, -5.4030e-02],\n",
      "          [ 7.2072e-04, -2.6088e-02,  4.5239e-02, -2.9466e-02,  1.4199e-02],\n",
      "          [ 4.5651e-02, -5.1033e-02,  4.3700e-02, -3.1720e-02, -6.7182e-02],\n",
      "          [ 7.7703e-02,  3.1985e-02,  5.9415e-02, -3.0404e-02,  6.7329e-02],\n",
      "          [ 5.0858e-02, -3.8882e-02,  5.9882e-02,  3.7880e-02, -7.3276e-02]],\n",
      "\n",
      "         [[ 1.5909e-02,  1.5396e-02, -4.1858e-02, -2.9638e-03, -1.5468e-02],\n",
      "          [ 7.1020e-02,  2.4310e-02,  7.0771e-02, -5.4427e-02, -4.4849e-02],\n",
      "          [-1.7822e-02, -6.3163e-02, -1.6100e-02,  6.3265e-04, -3.3182e-02],\n",
      "          [ 7.8653e-02,  3.3582e-02, -6.8647e-02, -2.7104e-02, -7.3919e-02],\n",
      "          [-2.1038e-02, -7.7078e-02,  2.1580e-02,  2.8063e-02,  7.6064e-02]],\n",
      "\n",
      "         [[-7.6001e-03, -4.5007e-02,  3.3765e-03, -4.9790e-02,  7.1974e-02],\n",
      "          [-4.7034e-02,  6.9698e-02, -7.1027e-02,  1.3699e-02,  9.1153e-03],\n",
      "          [-7.7346e-02,  5.1495e-02,  4.9454e-02,  2.6241e-02,  5.3875e-02],\n",
      "          [-5.2085e-02, -6.3609e-02, -8.0535e-02,  4.8179e-02,  6.7187e-02],\n",
      "          [ 1.8518e-03, -2.9899e-02,  1.0163e-02, -6.4690e-02, -3.3194e-02]],\n",
      "\n",
      "         [[-1.5717e-03, -2.1179e-02, -4.8847e-02,  6.4974e-02,  3.1256e-02],\n",
      "          [ 3.1410e-02,  6.2417e-02,  2.7683e-02, -6.4534e-02, -9.6072e-03],\n",
      "          [-4.3000e-02,  4.8542e-02, -6.7682e-02,  6.6327e-02, -1.5291e-02],\n",
      "          [-1.5902e-02,  5.5305e-02,  1.8566e-02,  3.1228e-02,  8.0579e-02],\n",
      "          [ 7.3573e-02,  7.8601e-02,  3.6102e-03,  7.0159e-02,  3.2006e-02]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0537, -0.0532,  0.0570, -0.0145,  0.0099,  0.0534,  0.0037,  0.0232,\n",
      "         0.0555, -0.0169,  0.0147, -0.0539,  0.0085,  0.0656, -0.0514,  0.0810],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0271, -0.0404,  0.0375,  ...,  0.0127,  0.0170,  0.0311],\n",
      "        [-0.0436,  0.0202, -0.0356,  ..., -0.0265, -0.0011,  0.0010],\n",
      "        [ 0.0111, -0.0341, -0.0311,  ...,  0.0054,  0.0403,  0.0276],\n",
      "        ...,\n",
      "        [ 0.0028,  0.0475,  0.0212,  ..., -0.0367, -0.0135, -0.0015],\n",
      "        [-0.0211,  0.0152, -0.0024,  ...,  0.0213,  0.0320, -0.0271],\n",
      "        [ 0.0237,  0.0186, -0.0037,  ...,  0.0237, -0.0227, -0.0367]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0257, -0.0368, -0.0042,  0.0119, -0.0319,  0.0055, -0.0324, -0.0158,\n",
      "        -0.0438, -0.0264, -0.0128,  0.0321, -0.0086,  0.0435,  0.0351,  0.0321,\n",
      "         0.0416, -0.0192, -0.0044,  0.0373,  0.0050, -0.0198, -0.0137,  0.0150,\n",
      "        -0.0177, -0.0487,  0.0262,  0.0234,  0.0452, -0.0057,  0.0300, -0.0470,\n",
      "         0.0048, -0.0231,  0.0071, -0.0197,  0.0224, -0.0074,  0.0485,  0.0173,\n",
      "        -0.0035,  0.0002, -0.0054, -0.0406,  0.0357,  0.0059,  0.0128,  0.0080,\n",
      "        -0.0374,  0.0443,  0.0343, -0.0488, -0.0467, -0.0373,  0.0267,  0.0281,\n",
      "         0.0052, -0.0278, -0.0272,  0.0198,  0.0266,  0.0423,  0.0232,  0.0385,\n",
      "        -0.0047, -0.0308,  0.0093, -0.0268, -0.0157, -0.0418,  0.0379, -0.0336,\n",
      "        -0.0051, -0.0424,  0.0323,  0.0083, -0.0177,  0.0059,  0.0205, -0.0362,\n",
      "         0.0190, -0.0141, -0.0002,  0.0468, -0.0300, -0.0436,  0.0412, -0.0084,\n",
      "         0.0262, -0.0002,  0.0498,  0.0056, -0.0012,  0.0179,  0.0357, -0.0463,\n",
      "         0.0366,  0.0403,  0.0076, -0.0300,  0.0446, -0.0246,  0.0106, -0.0088,\n",
      "         0.0367,  0.0329,  0.0205, -0.0398,  0.0147, -0.0248,  0.0201, -0.0281,\n",
      "         0.0133,  0.0241, -0.0085, -0.0112, -0.0080, -0.0406,  0.0063, -0.0008],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0688, -0.0331, -0.0093,  ..., -0.0761, -0.0688,  0.0868],\n",
      "        [ 0.0331,  0.0245, -0.0882,  ...,  0.0072, -0.0069, -0.0014],\n",
      "        [ 0.0125, -0.0564,  0.0592,  ..., -0.0832,  0.0479, -0.0640],\n",
      "        ...,\n",
      "        [ 0.0294, -0.0831, -0.0136,  ...,  0.0609,  0.0444, -0.0556],\n",
      "        [-0.0802,  0.0278, -0.0224,  ..., -0.0178, -0.0780,  0.0112],\n",
      "        [ 0.0703, -0.0128, -0.0300,  ...,  0.0289, -0.0624,  0.0543]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0135, -0.0378,  0.0393,  0.0393, -0.0347, -0.0818,  0.0311,  0.0155,\n",
      "        -0.0319,  0.0482,  0.0362,  0.0702,  0.0745,  0.0757, -0.0050,  0.0695,\n",
      "         0.0887,  0.0637,  0.0195,  0.0842,  0.0584,  0.0461, -0.0538,  0.0648,\n",
      "        -0.0223, -0.0091, -0.0913, -0.0149,  0.0609,  0.0510,  0.0866, -0.0510,\n",
      "        -0.0143,  0.0250,  0.0213, -0.0744, -0.0711,  0.0448,  0.0686, -0.0172,\n",
      "         0.0817, -0.0023,  0.0549, -0.0644,  0.0132, -0.0881, -0.0380,  0.0672,\n",
      "        -0.0767,  0.0882,  0.0759,  0.0477,  0.0406,  0.0883,  0.0789,  0.0912,\n",
      "        -0.0702, -0.0126,  0.0273, -0.0800, -0.0116,  0.0697, -0.0319,  0.0817,\n",
      "         0.0581,  0.0632,  0.0415, -0.0898, -0.0177,  0.0053, -0.0747, -0.0054,\n",
      "        -0.0839,  0.0137, -0.0360, -0.0403,  0.0461, -0.0151,  0.0362, -0.0056,\n",
      "        -0.0575, -0.0148,  0.0041,  0.0642], requires_grad=True), Parameter containing:\n",
      "tensor([[ 2.5353e-02, -3.8713e-02, -1.5187e-02,  1.0875e-01, -9.3462e-02,\n",
      "          9.4975e-02,  2.1466e-02,  7.7713e-02, -1.0156e-01,  9.8720e-02,\n",
      "          9.8412e-02,  6.8973e-02, -1.0947e-02,  1.6316e-02, -1.0032e-01,\n",
      "          5.5322e-02, -5.0273e-02, -5.9615e-02, -6.2494e-02, -4.2576e-02,\n",
      "          9.9623e-02, -4.1783e-02, -1.0269e-01, -9.2828e-02, -6.1450e-02,\n",
      "          3.0438e-03,  8.1260e-02, -6.8345e-02, -3.6921e-02,  2.8399e-02,\n",
      "         -2.8875e-02, -4.0643e-02,  4.8409e-02,  4.9415e-02, -6.9067e-02,\n",
      "          7.8656e-02,  2.4117e-02,  4.4297e-02, -1.9004e-02,  7.8403e-02,\n",
      "         -8.9600e-02, -6.6641e-02, -1.0127e-01, -4.1830e-02, -8.5148e-02,\n",
      "          9.6875e-02,  3.3849e-02, -5.3633e-02,  3.0290e-02, -2.7177e-02,\n",
      "          6.8277e-02, -1.0204e-01,  2.9183e-02, -4.5820e-02,  1.0849e-01,\n",
      "          1.9433e-02, -7.8974e-03, -6.6610e-02,  4.1657e-02,  7.1310e-02,\n",
      "         -7.6182e-03,  4.0579e-02,  3.4738e-02, -9.7776e-02, -9.5891e-03,\n",
      "         -2.0443e-02, -8.8189e-02,  9.0152e-02, -5.3531e-02, -8.6396e-02,\n",
      "         -4.1876e-02, -6.5064e-02,  5.8603e-02,  2.6852e-02,  6.2560e-03,\n",
      "          7.2366e-02, -7.9774e-02,  1.0537e-01,  3.3767e-02, -6.5748e-02,\n",
      "          4.6164e-02, -6.6878e-02, -5.7894e-02,  1.0165e-01],\n",
      "        [-1.0498e-01, -9.7677e-02, -8.9444e-02, -5.3905e-02, -5.1206e-02,\n",
      "         -4.4243e-02,  9.8351e-02, -6.8630e-02,  1.0494e-01,  9.4254e-02,\n",
      "          1.7705e-02,  8.5872e-02,  1.0723e-01,  3.2366e-03,  7.8131e-02,\n",
      "          6.0113e-02,  1.4648e-02,  3.1743e-02, -8.8382e-02,  5.0105e-02,\n",
      "          3.9326e-02, -1.3064e-02, -6.0672e-02,  3.3553e-02,  1.6359e-02,\n",
      "         -8.2091e-02,  5.8977e-02, -8.1782e-02, -9.1977e-02, -2.5833e-02,\n",
      "          6.9176e-03,  6.3296e-02,  1.0624e-01,  6.2203e-03,  6.9717e-02,\n",
      "         -5.7235e-02,  5.0895e-02, -1.0953e-02,  8.8856e-02,  5.0320e-02,\n",
      "         -7.2675e-02,  2.5035e-02,  4.9227e-02,  9.3456e-02,  4.8571e-02,\n",
      "         -1.3844e-02, -1.8411e-02, -3.3582e-02, -7.4689e-02, -5.9562e-02,\n",
      "          3.4536e-02,  2.7163e-02, -5.2910e-02, -9.6213e-02, -1.0101e-01,\n",
      "         -2.7972e-02, -9.6788e-03,  4.6664e-02,  3.9301e-03, -5.4816e-03,\n",
      "         -7.9105e-02,  9.2797e-02, -2.3868e-02, -7.0099e-02, -6.2863e-02,\n",
      "         -4.3612e-02, -9.9265e-02,  4.8168e-02, -2.2806e-02, -7.9656e-02,\n",
      "         -1.0393e-01, -1.4493e-02,  1.0636e-01, -7.0750e-02, -7.2034e-02,\n",
      "          6.5878e-02, -2.7154e-02,  1.0759e-01,  8.0913e-02,  9.0565e-02,\n",
      "          2.5567e-02,  6.9856e-02, -9.3095e-02, -6.5359e-02],\n",
      "        [-9.5124e-02, -6.0148e-02,  4.6487e-02,  4.8038e-02, -1.1191e-03,\n",
      "         -7.5311e-02, -6.8472e-02, -2.3037e-02, -1.9456e-02, -5.7818e-02,\n",
      "         -4.8059e-02,  9.3659e-02,  2.0638e-02, -1.3032e-02, -3.3166e-02,\n",
      "          1.0041e-01,  3.6511e-02, -1.8379e-02, -2.6255e-02, -4.8127e-02,\n",
      "         -4.0182e-02,  1.0746e-02, -1.0273e-01,  4.3692e-02, -1.0340e-01,\n",
      "         -1.0123e-01, -5.2910e-02,  6.0078e-02, -3.9970e-02, -2.3084e-02,\n",
      "          3.9438e-02, -6.3600e-02, -3.1728e-02, -8.3584e-02,  2.9365e-02,\n",
      "          5.1186e-02, -5.4413e-02,  1.8713e-02,  1.0649e-02,  9.1166e-02,\n",
      "         -3.3297e-02, -2.2950e-02,  2.7850e-02, -5.5864e-02, -1.2429e-03,\n",
      "          1.4672e-02,  7.3102e-02, -4.8987e-02,  7.4093e-03,  9.4977e-02,\n",
      "          6.0522e-02, -5.3354e-03,  9.0514e-02, -3.5346e-02,  6.5144e-03,\n",
      "          4.2843e-02,  9.5280e-03, -3.5107e-02,  1.1202e-02, -1.3635e-02,\n",
      "         -1.1447e-02, -1.0145e-01, -8.3155e-02,  1.0587e-03, -1.5077e-02,\n",
      "          5.2787e-02,  1.0681e-01,  5.8185e-02,  8.6814e-02, -5.9435e-02,\n",
      "          4.1425e-02,  6.7195e-02, -6.0193e-02,  1.4075e-02,  8.9835e-03,\n",
      "          7.7219e-02, -1.2437e-02,  1.0855e-01, -9.0777e-02, -6.1448e-02,\n",
      "         -9.7847e-02,  7.4206e-02,  6.6924e-02,  7.5218e-03],\n",
      "        [ 5.2615e-02,  1.5685e-02,  6.5604e-02, -8.7310e-02, -4.5589e-02,\n",
      "          7.9548e-02,  3.2984e-02, -7.9717e-03,  7.8840e-02, -7.4232e-03,\n",
      "          3.7584e-02,  1.6736e-02, -1.5602e-02, -5.2230e-02, -1.0385e-01,\n",
      "          1.0569e-01,  3.0964e-02,  7.8519e-02,  4.7327e-02,  1.8046e-02,\n",
      "         -8.1209e-02,  3.8219e-02,  2.5536e-02,  8.4477e-02, -7.9914e-02,\n",
      "          4.1512e-02, -8.1785e-02, -4.1661e-02,  8.8378e-02, -7.2280e-02,\n",
      "          5.4221e-02,  2.3979e-02, -8.7657e-02, -7.6841e-02, -9.0654e-02,\n",
      "          8.3950e-02, -9.3735e-04,  2.5667e-02, -6.9094e-02, -5.4313e-02,\n",
      "         -6.1798e-03,  5.7947e-03, -3.2142e-03, -3.7509e-02, -7.8866e-03,\n",
      "         -7.9325e-03, -7.0535e-02,  4.6806e-02, -3.0083e-02,  2.4200e-02,\n",
      "          5.7673e-02,  7.3790e-02,  4.7225e-02,  4.2268e-03,  4.4345e-02,\n",
      "          4.6970e-02,  8.4850e-02, -3.1467e-02, -1.0347e-01, -1.9921e-02,\n",
      "         -3.2164e-02, -1.0489e-01,  6.2501e-02,  3.0566e-02, -2.8091e-02,\n",
      "          5.6992e-02, -5.5955e-02, -6.0458e-02, -9.5191e-03, -8.7892e-02,\n",
      "          6.2965e-02,  6.4175e-02, -1.7329e-02,  3.1537e-03, -1.1636e-02,\n",
      "          8.5966e-02,  9.2000e-02,  2.1288e-02, -8.8463e-02,  5.9127e-02,\n",
      "          9.1428e-02, -1.0826e-01, -3.4376e-02,  8.5958e-02],\n",
      "        [ 6.5585e-02,  2.3043e-02, -2.8321e-03,  8.0835e-02, -1.3392e-02,\n",
      "         -6.9435e-02,  5.3980e-02,  8.0903e-02, -1.5741e-02,  4.0179e-04,\n",
      "         -4.7347e-02, -3.2147e-02, -1.0258e-01,  3.5738e-02,  6.7219e-02,\n",
      "         -1.0238e-01, -3.8908e-02, -2.1888e-02, -8.2817e-02, -9.8119e-02,\n",
      "         -5.8907e-02,  4.0109e-03, -7.7733e-02,  9.6745e-03, -1.0740e-01,\n",
      "         -2.5304e-02, -7.4827e-02,  8.8303e-02,  9.3888e-02,  6.6185e-04,\n",
      "          5.1635e-02, -6.9779e-02, -5.2796e-02, -9.9044e-02, -1.0492e-01,\n",
      "         -6.0757e-02, -9.0065e-02, -8.8620e-02, -1.2886e-02,  6.7041e-02,\n",
      "         -4.5176e-02,  4.9185e-02,  1.9346e-02, -4.3953e-02, -3.2836e-02,\n",
      "         -9.9019e-02, -1.0579e-01,  8.8981e-02, -2.0271e-02, -1.0597e-01,\n",
      "         -6.3286e-02,  1.9041e-02,  3.9239e-02,  3.8060e-02,  7.7629e-02,\n",
      "          9.7427e-02,  4.3781e-02,  2.3363e-02, -1.4789e-02, -8.8742e-02,\n",
      "         -3.7749e-02,  6.5261e-02,  4.2995e-02, -1.0348e-01, -6.5529e-02,\n",
      "         -6.4593e-02, -9.1466e-02, -5.4649e-02,  2.0312e-02, -1.0757e-01,\n",
      "          6.1666e-02, -1.0631e-01, -8.2335e-02,  4.5054e-02, -5.9440e-02,\n",
      "         -3.5796e-03, -1.0174e-01,  1.4710e-02,  3.5959e-02, -8.1315e-02,\n",
      "          6.1545e-03,  6.6455e-02, -1.0590e-01, -9.4653e-02],\n",
      "        [ 3.3576e-02, -9.8284e-02, -3.8107e-02, -3.6296e-02, -3.7688e-02,\n",
      "          2.0471e-04,  8.3347e-02,  7.1086e-02, -7.8121e-02,  3.3933e-02,\n",
      "          9.3563e-02,  9.1238e-02, -1.3501e-02, -2.0420e-02,  4.1206e-02,\n",
      "          8.0219e-02, -2.8248e-02, -9.5568e-02,  3.2832e-03, -1.5297e-02,\n",
      "          8.8557e-02, -8.2611e-02, -9.5883e-02, -1.0026e-01, -8.5908e-02,\n",
      "          5.7821e-03,  6.2632e-02,  2.0936e-02,  7.5918e-02,  8.5002e-02,\n",
      "          5.2688e-02, -7.4248e-02, -8.3370e-02, -4.1232e-02, -5.7172e-02,\n",
      "          8.3184e-03, -5.9855e-02,  6.8820e-02, -2.5271e-02, -7.8982e-02,\n",
      "         -7.0064e-02,  1.5041e-02,  1.0862e-01, -3.6451e-02, -7.3958e-02,\n",
      "          9.8354e-02, -7.9620e-02, -1.9259e-02,  7.4346e-02, -1.4444e-02,\n",
      "         -8.6865e-02,  1.9514e-02,  6.7472e-02,  9.2414e-02, -1.0573e-01,\n",
      "          5.7975e-02,  6.5940e-02,  5.4500e-02,  4.0502e-02, -1.0388e-02,\n",
      "         -8.2603e-03, -3.5376e-02, -9.7513e-02,  1.0818e-02,  1.0086e-01,\n",
      "         -6.5583e-02,  1.0339e-01, -9.9502e-03,  3.8715e-03,  4.4308e-02,\n",
      "          2.7236e-02,  5.5993e-02,  2.0860e-02,  8.9399e-02,  2.2985e-02,\n",
      "          1.7004e-02, -3.7160e-02,  5.6357e-02,  4.0537e-02, -9.9381e-03,\n",
      "          8.5422e-02, -6.5498e-02, -1.6380e-02,  9.9127e-02],\n",
      "        [ 1.6197e-02,  1.0280e-02, -3.8653e-02, -4.8576e-02,  2.9294e-02,\n",
      "          1.0698e-01,  3.8788e-02,  1.1113e-02, -1.0094e-01, -2.1858e-02,\n",
      "          9.7995e-02, -8.6518e-03,  7.7650e-02, -1.0799e-02,  2.2358e-02,\n",
      "          2.7002e-02,  5.2180e-02, -8.4746e-02,  2.7544e-02,  7.5885e-02,\n",
      "         -1.6291e-02,  9.4562e-02,  2.1783e-02,  4.2323e-02,  5.2942e-03,\n",
      "         -4.6897e-02, -2.0938e-02, -6.2029e-02,  7.2198e-02, -9.1499e-02,\n",
      "         -7.5671e-02,  6.7764e-03,  8.5069e-02,  5.6229e-02, -1.0383e-01,\n",
      "         -9.8024e-02,  8.0870e-02, -6.9803e-02,  5.5154e-02, -6.8310e-02,\n",
      "         -1.0340e-01, -5.0258e-02, -1.1694e-02,  1.0559e-01,  1.0180e-01,\n",
      "          8.7409e-02,  1.0229e-02,  1.5964e-02, -4.3371e-02, -1.2729e-02,\n",
      "         -2.2484e-02, -3.5489e-02,  6.1804e-02, -8.0275e-02,  9.5633e-02,\n",
      "         -1.3212e-02,  1.3563e-02, -4.7224e-02,  2.2650e-02, -7.8902e-02,\n",
      "          4.1302e-02, -5.0091e-02, -5.9800e-02, -1.0648e-01,  4.7500e-02,\n",
      "          1.0835e-01,  2.4954e-02, -1.6258e-02, -8.7154e-02, -4.6415e-02,\n",
      "         -5.3551e-02, -4.6343e-02,  3.6320e-02,  3.1885e-02,  7.5066e-02,\n",
      "         -5.6407e-02,  6.8212e-02,  9.2131e-02, -1.0258e-01, -4.5315e-02,\n",
      "          4.9934e-02, -7.6234e-02,  2.2448e-02, -5.8929e-02],\n",
      "        [ 1.0438e-01,  9.9003e-02, -8.1429e-02,  6.1949e-02, -6.5834e-02,\n",
      "          9.3486e-02, -1.1033e-02,  7.9446e-02, -6.2150e-02,  5.0609e-02,\n",
      "         -2.5102e-03,  2.3027e-02, -7.4771e-02,  1.0814e-01,  6.3736e-02,\n",
      "         -4.2205e-02, -8.0442e-02, -8.0690e-02,  3.4166e-02, -9.8357e-02,\n",
      "         -8.9662e-02, -3.8977e-02,  8.8164e-03,  3.1324e-02, -8.6616e-02,\n",
      "         -6.7860e-02,  6.5271e-02, -8.3076e-03, -1.6870e-02,  5.7935e-02,\n",
      "          9.5910e-02,  1.3346e-02,  9.4975e-02,  9.9087e-02,  5.1762e-02,\n",
      "          3.8370e-03, -2.3968e-02, -8.6252e-02, -5.6382e-02,  7.1611e-02,\n",
      "         -3.8037e-02, -8.5396e-02,  1.0222e-01, -9.2682e-02,  9.1312e-02,\n",
      "         -8.3839e-02, -5.3024e-02,  4.8988e-02,  3.4843e-02, -6.5983e-02,\n",
      "         -6.7626e-03, -3.6845e-02,  7.7697e-02,  7.7478e-02,  7.1753e-02,\n",
      "         -6.3902e-02,  7.7141e-02, -6.5315e-02,  4.5365e-02,  5.1282e-02,\n",
      "         -7.0449e-02, -4.7633e-02, -1.8672e-02, -9.3255e-02, -7.3300e-02,\n",
      "          7.5146e-02,  3.9875e-02,  7.1098e-02, -4.2648e-02, -4.3196e-02,\n",
      "         -6.3058e-02,  1.7942e-03, -8.2097e-02, -2.7329e-03, -7.3158e-02,\n",
      "         -1.8793e-02,  5.0182e-02, -1.8641e-02, -5.3687e-02, -6.4869e-02,\n",
      "          3.4532e-02,  5.1458e-02,  5.5014e-02, -5.1421e-02],\n",
      "        [-3.9103e-03,  4.3308e-02,  4.7693e-02, -5.0045e-02, -3.4026e-02,\n",
      "          5.1560e-02,  4.6875e-02,  7.2846e-03, -2.9547e-02, -7.4023e-02,\n",
      "          1.4659e-02,  3.4002e-02, -1.1469e-03, -6.9009e-02,  7.7635e-02,\n",
      "          4.3909e-02, -9.8655e-02, -2.0647e-02,  2.0591e-02,  1.0736e-01,\n",
      "         -5.4240e-02,  4.4038e-02,  4.0541e-02, -3.1533e-02,  2.7046e-02,\n",
      "         -2.8330e-02,  1.8949e-02, -7.8992e-02,  5.9984e-02, -1.3425e-02,\n",
      "          9.4484e-02,  6.8664e-02, -6.9221e-03, -4.0316e-02, -8.5372e-03,\n",
      "          7.4236e-02,  6.2800e-02, -9.4488e-02, -3.0699e-02,  1.3963e-02,\n",
      "         -3.6011e-02, -7.0240e-02,  1.6723e-02,  8.0089e-02,  8.5110e-02,\n",
      "         -1.0304e-01, -9.1302e-02, -9.5040e-02, -7.0116e-02,  7.1563e-02,\n",
      "          3.9507e-02,  2.7404e-02,  1.4262e-02,  5.0986e-02,  2.4871e-02,\n",
      "          7.9124e-02, -7.2490e-02, -3.6405e-03,  1.0258e-01, -8.9861e-02,\n",
      "          7.7718e-02, -8.6996e-02, -3.9616e-02, -8.3574e-02, -7.5960e-02,\n",
      "          2.8735e-02,  5.7731e-02, -5.4573e-03, -3.9446e-02,  5.7675e-02,\n",
      "         -1.8898e-02,  4.1418e-02, -1.8868e-02,  3.3049e-02, -3.3334e-05,\n",
      "          7.4368e-02, -6.3915e-02,  5.7457e-02, -6.7223e-03, -4.5776e-02,\n",
      "         -9.1848e-02, -9.7456e-02,  1.0356e-01,  1.3071e-02],\n",
      "        [ 4.5087e-02, -3.9343e-02,  1.7185e-02, -1.0302e-02,  1.0758e-01,\n",
      "         -1.0633e-01,  9.5774e-02, -9.3148e-03, -7.4319e-02,  8.6243e-02,\n",
      "         -4.3599e-02, -1.0510e-01, -6.2596e-02, -5.2491e-02,  1.0571e-02,\n",
      "          6.7459e-02,  2.1525e-02, -4.9203e-02,  9.2084e-02,  4.3851e-02,\n",
      "          3.1202e-02, -5.1992e-02,  8.9410e-03,  6.8814e-02,  4.6150e-02,\n",
      "         -9.2502e-02,  9.1636e-02,  6.6190e-02,  3.7105e-02,  5.1924e-02,\n",
      "         -6.6360e-02, -9.9361e-02, -6.4012e-02, -4.0833e-03, -9.8732e-02,\n",
      "          4.0887e-02,  2.9927e-02, -2.0203e-02, -4.7020e-02, -4.7967e-02,\n",
      "         -8.9049e-02,  4.7018e-02, -7.7621e-02, -1.0864e-01,  8.5896e-02,\n",
      "         -1.0059e-01,  4.3581e-02,  9.2452e-02,  8.1935e-02,  4.6790e-02,\n",
      "         -3.3861e-02,  5.7468e-02, -1.9883e-02,  1.0117e-01,  9.2837e-02,\n",
      "          3.8357e-02, -1.8938e-02,  1.9448e-02, -8.5911e-02,  3.0219e-02,\n",
      "         -9.0209e-02, -4.2615e-02,  3.4115e-02,  1.0198e-01,  9.0184e-02,\n",
      "         -6.5092e-03, -3.9694e-02,  7.9256e-02, -3.5372e-02,  2.4046e-02,\n",
      "         -1.0212e-01,  5.1477e-02, -3.3285e-02, -1.0601e-01, -9.6707e-02,\n",
      "          5.3387e-03,  8.2978e-02, -8.8941e-02, -3.2790e-02, -1.8116e-02,\n",
      "         -9.5070e-02,  9.6346e-02,  8.2822e-03, -6.1969e-03]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0790, -0.0824,  0.0200, -0.0990, -0.0447, -0.0552,  0.0223, -0.0640,\n",
      "         0.0406, -0.0096], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2642c2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1010, -0.0959,  0.0516, -0.0998, -0.1566, -0.0059,  0.0391, -0.0844,\n",
      "          0.0312, -0.0267]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Letâ€™s try a random 32x32 input. Note: expected input size of this net (LeNet) is 32x32\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22929f5",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537151ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26470ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1010, -0.0959,  0.0516, -0.0998, -0.1566, -0.0059,  0.0391, -0.0844,\n",
      "          0.0312, -0.0267]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed831e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [2, 4]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2],[2,4]]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e0809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2]],\n",
      "\n",
      "         [[2, 4]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a.unsqueeze(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bad06b",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "``torch.nn`` only supports mini-batches. The entire ``torch.nn`` package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "\n",
    "For example, nn.Conv2d will take in a 4D Tensor of ``nSamples x nChannels x Height x Width``.\n",
    "\n",
    "If you have a single sample, just use ``input.unsqueeze(0)`` to add a fake batch dimension.\n",
    "\n",
    "## Recap\n",
    "\n",
    "- ``torch.tensor`` - *a multidimensional array* with support autograd and also stores the gradient with respect to that tensor\n",
    "- ```nn.Module``` - Neural network module.*Convenient way of encapsulating parameters*\n",
    "- ```nn.Parameter``` -  kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a Module.\n",
    "- ```autograd.Function``` - Implements ``forward`` and ``backward`` definitions of an autograd operation. Every Tensor operation creates at least a single Function node that connects to functions that created a Tensor and encodes its history.```\n",
    "\n",
    "## Loss\n",
    "\n",
    "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\n",
    "\n",
    "There are several different loss functions under the nn package . A simple loss is: nn.MSELoss which computes the mean-squared error between the output and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c5be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0263, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b396fee4",
   "metadata": {},
   "source": [
    "Now, if you follow loss in the backward direction, using its .grad_fn attribute, you will see a graph of computations that looks like this:\n",
    "\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d<br>\n",
    "      -> flatten -> linear -> relu -> linear -> relu -> linear(output probabilities)<br>\n",
    "      -> MSELoss<br>\n",
    "      -> loss\n",
    "      \n",
    "So, when we call loss.backward(), the whole graph is differentiated w.r.t. the neural net parameters, and all Tensors in the graph that have requires_grad=True will have their .grad Tensor accumulated with the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0364521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x000001DF6577D520>\n"
     ]
    }
   ],
   "source": [
    "# mse loss\n",
    "print(loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b7da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddmmBackward0 object at 0x000001DF4F0826D0>\n"
     ]
    }
   ],
   "source": [
    "# linear layer of output probab\n",
    "print(loss.grad_fn.next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba72944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AccumulateGrad object at 0x000001DF65791580>\n"
     ]
    }
   ],
   "source": [
    "# ReLU layer\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ecc240f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 bias before backward None\n",
      "Conv2 bias after backward tensor([ 0.0007, -0.0157,  0.0008,  0.0151,  0.0213, -0.0062])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "# gradients are now set to zero\n",
    "print(\"Conv1 bias before backward\",net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print(\"Conv2 bias after backward\",net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f9a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can update the weights using gradient descent\n",
    "# wt = wt - learning rate * gradient\n",
    "\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data*learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73bdaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this weight updates happen in an optimizer `torch.optim`\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr = 1e-3)\n",
    "\n",
    "# in training loop \n",
    "optimizer.zero_grad()\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d45a0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()# Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ed659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
